import numpy as np
from mnist_loader import load_data
import matplotlib.image as img
import random
import math

training_data, validation_data, test_data = load_data()
training_img = np.asarray(training_data[0])
training_vals = np.asarray(training_data[1])

def save_as_png(dataset, number):
    folder = './images/'
    for i in range(number):
        img.imsave(folder + '%s__%s.png' % (str(i), str(training_vals[i])), training_img[i].reshape(28,28))


def init_weights(number):
    return [0 for i in range(number)]

def init_b():
    return random.random()

def calc_z(W, X, b):
    sum = 0
    assert len(W) == len(X)
    for i in range(len(W)):
        sum += W[i] * X[i]
    return sum + b

def calc_sigmoid(z):
    return 1/(1+math.exp(-z))

def calc_cost(Y, A):
    sum = 0
    assert len(Y) == len(A)
    for i in range(len(A)):
       sum += Y[i] * math.log(A[i]) + (1 - Y[i]) * math.log(1 - A[i])
    return -sum/len(A)

def calc_loss(Y, A):
    - Y * math.log(A) - (1 - Y) * math.log(1 - A)

def normalize_val(val, target_val):
    result = 0
    if val == target_val:
        result = 1
    return result


def calc_dw(X, A, Y):
    dws = []
    A_Y = [A[i] - Y[i] for i in range(len(A))]

    for i in range(len(X[0])):
        sum = 0
        for j in range(len(A_Y)):
            sum += X[j][i] * A_Y[j]
        dws.append(sum/len(X))
    return dws

def calc_db(Y, A):
    sum = 0
    for i in range(len(Y)):
        sum += A[i] - Y[i]
    return sum/len(Y)


def propagate(W, b, X, Y):
    A = [calc_sigmoid(calc_z(W, X[i], b)) for i in range(trainig_sets)]
    cost = calc_cost(Y, A)
    # grads = {'dw': calc_dw(X, A, Y), 'db': calc_db(Y, A)}
    dw = calc_dw(X, A, Y)
    db = calc_db(Y, A)
    return dw, db, cost


def optimize(W, b, X, Y):
    num_iterations = 200
    learning_rate = 0.1

    for i in range(num_iterations):
        dw, db, cost = propagate(W, b, X, Y)
        for j in range(len(W)):
            W[j] -= learning_rate * dw[j]
        b -= learning_rate * db
        print cost
    #print "final cost " + str(cost)
    return W, b

def predict(W, b, x):
    return calc_sigmoid(calc_z(W, x, b))


def sum_up(result, real_value):
    print "the given picture is %s with a probability of %s" % (str(real_value), str(result))

#W, b = optimize(W, b, X, Y)
#W = [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -8.83696008504986e-05, -0.009956989785922852, -0.024214121403301276, -0.024503028697039544, -0.018464704679209274, -0.010351275770529855, -0.0032960999290449744, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -9.660447453093107e-05, -0.000941893626676578, -0.001883787253353156, -0.0032347367442074897, -0.01343093436346394, -0.02970034851090634, -0.03975643159230247, -0.04408931658588022, -0.036211540551177666, -0.014591698685797103, -0.0021973999526966473, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0014007648806985003, -0.002241601246894846, -0.005816964329136693, -0.01786003867492296, -0.04196912047111705, -0.06323388661610797, -0.07540619636153192, -0.08243091303466303, -0.057457540929674734, -0.020326797345145284, -0.017863821478550486, -0.009974979284462929, -0.0007790857332863619, 0.030868191388673395, 0.031031515152634616, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0010381651303601825, 0.0011959896144592304, -0.0006617213018742577, -0.002910376629454371, -0.0035334693830175097, -0.005081294468012742, -0.006897550885685028, -0.02314999593515983, -0.04896275376297536, -0.05933247863599205, -0.0719303682708434, -0.11531700750076208, -0.141758559336711, -0.1173118083273258, -0.05480158524829408, 9.108750171931353e-05, -0.013964043618663092, -0.03014745591591593, 0.029141568346844792, 0.04772757799919247, 0.027122391724427184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.01011653436553467, 0.023250065208654445, 0.008328629195839555, -0.017629512263588363, -0.02136024992357175, 0.0018934670122209183, -0.013182396309286077, -0.04445505731297816, -0.05655634613835507, -0.058506258401573176, -0.09437558401021601, -0.12716954904368272, -0.1551576979922082, -0.11915901590384968, -0.09460065050586595, 0.01131335698576944, 0.025082346259152514, 0.03750671260804675, 0.11319198829235327, 0.09856472806808168, 0.04375303109159142, -0.00570617563606007, -0.002583288617175105, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0006199486438130723, 0.010766441838345443, 0.008443512225714258, -0.024307585305603185, -0.020434173602217855, -0.010214374224728533, -0.025990439459167257, -0.06286307062855348, -0.07303118125525558, -0.10027929793312713, -0.172738759212156, -0.235836665657042, -0.22315072375688313, -0.18675398513505148, -0.08210464328604465, 0.04479714095014378, -0.02105061108675464, 0.0231392465260057, 0.09208105353315409, 0.06690039834545981, 0.005191218476936832, -0.03024990310342119, -0.02475922936635104, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0021766997495839963, 0.014871381422976048, 0.00016578569291413815, -0.013225444320140299, -0.0014113729859513318, -0.024874628365001605, -0.014338461003120934, -0.04437029902080679, -0.07422830774209115, -0.1278367695615524, -0.195281108198013, -0.26964572699349504, -0.25528060086097004, -0.14435274732750566, -0.0695143264644154, -0.045821501701024746, -0.08855076716986411, -0.03288815960930697, 0.029511263477878125, 0.027453312872823796, 0.014099753325239748, -0.039673246028065906, -0.036739144876993195, 0.0, 0.0, 0.0, -0.004058277573330983, 0.0, 0.0022653580533975597, 0.030164707227820848, 0.008809383340356216, -0.00023241505645265205, 0.02123801217092039, -0.005619021789103245, 0.025488178737621527, -0.05707632564374736, -0.10093229959191828, -0.09222766581550719, -0.08082136850664891, -0.15697808601090285, -0.21723795944210972, -0.0968431176720157, -0.023944135947795334, -0.10050170442877485, -0.08046084117890791, -0.03348336956254123, 0.002898973204248574, 0.019336957274183855, 0.011855864342248354, -0.015589437688115321, -0.011125239724639326, 0.0, 0.0, 0.0, -0.00046826279692280585, 0.0, -0.0022322884620725536, 0.022371991138649794, 0.03886075384686785, 0.02195367637060612, 0.042831986066265586, 0.0175104655191379, 0.04466189483549406, -0.024676763698732073, -0.11207015192787351, -0.02355100736160375, -0.008068405255797164, -0.09007917258261146, -0.18071310829994264, -0.025491698577239454, -0.03257139132574997, -0.10819030109920734, -0.04893423424108257, 0.007517190680855665, 0.0055516965886610245, 0.011497636606861608, 0.008818215260122267, -0.003077193966389601, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.008136402530343704, 0.023381562924058828, 0.03827637196721238, 0.01757580747311116, 0.03175333443185123, -0.001060181034698101, 0.051958212008166804, -0.028250184602471244, -0.04871927063573202, -0.004056978932361546, -0.044408327952708215, -0.1724896863514892, -0.1588736624384832, 0.029542559428120473, -0.02699705115419124, -0.06811410476237414, 0.0067591260859111435, 0.024629950275300565, 0.03625955435096359, 0.017040321220251852, 0.009619267319241459, -0.0027202649851157438, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0107807333527054, 0.028364129227637907, 0.02575873217762503, 0.024967647360394203, 0.012383209492150011, 0.011237569875051808, 0.07549096681593866, 0.04859045906732902, -0.0193750853074775, -0.020240990753043284, -0.13476758549691467, -0.15615371119713914, -0.06780096372223775, -0.0017620107527037486, -0.0420263494491626, -0.026039887293365958, 0.035685980873495636, 0.019290344475798294, 0.02757024924465636, 0.009332095174064055, -0.013201706797529768, -0.00811307100823994, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0107807333527054, 0.03884523575105788, 0.017058458411290205, 0.043514962482462, 0.02690945111092002, 0.03639063774421316, 0.10426028601368131, 0.1555550089693224, 0.060813456277953, -0.003547083967968028, -0.11725045755167066, -0.10334253741548965, -0.08437424470056722, -0.043730489275765345, -0.024945364630455824, 0.046225695340167045, 0.04426373135944965, 0.027924458452327834, 0.009163583323222728, 0.01315059138700617, -0.005219600753651168, -0.009449341527244162, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0107807333527054, 0.04120584532840472, 0.025324346906747577, 0.06782275466919803, 0.0810367589015488, 0.11035838153122846, 0.12513814255241335, 0.09662084130153577, 0.10457831173148811, 0.08766234223329228, 0.02560111584506336, 0.015282412479274582, -0.004713248943285123, 0.0038592324053712836, 0.050830954938823225, 0.09582862124491723, 0.10484098736100801, 0.04947441949468265, 0.03645205313676169, 0.024144976705063784, 0.006894154389180266, -0.020329330800336623, -0.00110588006532293, 0.0, 0.0, 0.0, 0.0, 0.0, 0.010170503162929624, 0.04113804197398517, 0.050738866620043385, 0.10083076775818106, 0.14693966196446903, 0.18380295690004972, 0.13285928321856333, 0.06223309786867338, 0.117229635590636, 0.12576064466733666, 0.09657234392354767, 0.09167815403537269, 0.0901982137433661, 0.11943098755871653, 0.1372729930781444, 0.18608075518171388, 0.10287466002677258, 0.004257481453597648, -0.009662976153770073, 0.0023298380627295285, -0.002800551800765896, -0.0252134842294439, -0.004536943857735095, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.024404017451164297, 0.04807233700782738, 0.10837570339556796, 0.16258020842710266, 0.13622966357108596, 0.10286742019213133, 0.036836725479207424, 0.04368531782014585, 0.04333159777709017, 0.007665292832104725, 0.001226112665470206, 0.016754265928863123, 0.08396010047302092, 0.1326391803457913, 0.1428794443099898, 0.008464358377132606, -0.0661055815060041, -0.040063449842060825, 0.0045997101746090676, 0.016080290453990072, -0.013105351183017774, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0003698311649894056, 0.016442487807765502, 0.08233095193301115, 0.06411518784067173, -0.004500112879498828, -0.03263629109340253, -0.042262120795660815, -0.046960129427555085, -0.01129671705600694, 0.012217038834293672, -0.08034934033242955, -0.0435438430326963, 0.07486660121987207, 0.09533893942816193, 0.08577140152119006, -0.026155673338627488, -0.05471459798477561, -0.027527499488696466, -0.0021100738880554582, 4.101391115213219e-05, -0.01312119526320873, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0008792705455833277, -0.008953434475871606, 0.0033878026433915936, -0.017223942027425557, -0.022127509615917546, -0.01949275566360167, -0.05991942499325429, -0.028464605757393385, -0.0015665713938157347, 4.906378512818359e-05, -0.09348694118581857, -0.07805844083976644, 0.011211899862931378, 0.042360873772001435, 0.011719989592823981, -0.05962871191060114, -0.020914835497829094, -0.01686857345510443, -0.01635461684254473, -0.018839414460185975, -0.01410002026530726, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0004285345245115337, -0.0185175825727322, -0.03428269231700483, -0.04590979457297067, -0.05302679322562595, -0.07003016012916409, -0.09713383625607064, -0.06172487984283581, -0.04078665021384037, -0.06927986991930023, -0.1514327106831789, -0.11637808660176742, -0.026191764188906733, 0.013253378580799323, -0.010658733798870789, -0.021052852373788514, 0.006407789391369133, -0.009048487340464782, -0.01478259664320356, -0.017835778243490624, -0.006159076578015292, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0007191349761157488, -0.02031306615036689, -0.0507033597595508, -0.08502892353274377, -0.10990891212688578, -0.14402607564776346, -0.16841735469698738, -0.12365444441545849, -0.08959992963073626, -0.1217985106829896, -0.1837568769386842, -0.12563449318841363, -0.05924942689551272, 0.010354575766768518, 0.001178029192231273, 0.017937489976612042, 0.010993857084500078, 0.008928270734710194, -0.015533614694973906, -0.012964085749933255, -0.0013341755734191958, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0007807774961530068, -0.015153686853187956, -0.0427603042044518, -0.07991405919571679, -0.10959149997412863, -0.143659185099349, -0.14701826155320097, -0.09066472311606258, -0.12922140133270815, -0.18995629950884632, -0.1784473729192258, -0.0782179080484496, -0.04938239207127835, 0.010049857406452475, 0.033805952587560376, 0.02219838594678469, 0.005587161760754123, 0.009098221200933196, -0.0160197656655077, -0.004148471325414541, -0.002725858714658184, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0007162038006786655, -0.0071932152051277, -0.023811691902441944, -0.04688622860351621, -0.08099639918750647, -0.09983767704370969, -0.04214089953292478, -0.08291953983708306, -0.13627889791044093, -0.1856981809734684, -0.12837462721075452, -0.03903707282541585, -0.036690309844194566, 0.023062087618144544, 0.03153070492548226, 0.029764951956930245, -0.0024433946269785995, 0.0054172535923027385, -0.0005109530195996345, -0.0004935068859178879, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0007425721864911161, -0.003775254601607197, -0.015162926551157542, -0.03156775300672265, -0.059282300835606316, -0.05100183400694232, -0.025810869604238174, -0.054128392732866175, -0.12001413035824003, -0.1299384101303666, -0.08648912601676575, -0.005570342951398875, 0.0020636342571419414, 0.05884960295791097, 0.03970167659526346, 0.010433159358161692, 0.0065315413783866485, 0.0008175874745395201, -0.0006992496097906993, -0.0017571836089500545, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.001302690505910129, -0.002423387485259282, -0.003948776703230858, -0.01685424388038247, -0.0426335993977383, 0.01079840685968601, -0.014345372150474748, -0.08416880332637063, -0.07897824990853242, -0.060555796553162705, -0.03410230767579491, -0.03691334700778604, 0.03852983669619833, 0.06524881735242802, 0.03421253941805013, -0.00047270479437626616, -0.007599959786028836, -0.003262283538630745, -0.00020086220615528458, -0.0007402603288768319, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.0014823783277447765, -0.016588754832218507, -0.028868580915857495, 0.08748173799240791, 0.027898850526315584, -0.03135094724689505, -0.04200654967206078, -0.02107351365835127, 0.004693766387041903, -0.030842506362206062, -0.021337788635488245, -0.008806227128820596, -0.005120380933609428, -0.0006181184844384737, -0.00010907973254796596, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.00027456550931117407, -0.01011976062489229, -0.02537758168603472, 0.019314311860882203, 0.003920484720204113, -0.021206103458812246, -0.009664960953639327, -0.024955374596485353, -0.03698770459559092, -0.029449254058216946, -0.015259777853905443, -0.006464419259143497, -0.009849819398165122, -0.0016416365663608533, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, -0.006020392821167601, -0.012658001018308803, -0.00940331049105846, -0.0016371882881982803, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]
#b = -0.0831435817094


#image_index = 843
target_number = 9
trainig_sets = 200
W = init_weights(784)
b = 0
X = [training_img[i] for i in range(trainig_sets)]
Y = [normalize_val(training_vals[i], target_number) for i in range(trainig_sets)]

W, b = optimize(W, b, X, Y)

true_rec, false_rec, true_unrec, false_unrec = 0, 0, 0, 0

for i in range(400, 500):
    result = predict(W, b, training_img[i])
    fact = training_vals[i]

    if result >= 0.5 and fact == target_number:
        print str(i) + "success! %s - %s" % (str(result), str(fact))
        true_rec += 1
    elif result >= 0.5 and fact != target_number:
        print str(i) + ">>>false recognition! %s - %s" % (str(result), str(fact))
        false_rec += 1
    elif result < 0.5 and fact != target_number:
        print str(i) + "success! %s - %s" % (str(result), str(fact))
        true_unrec += 1
    elif result < 0.5 and fact == target_number:
        print str(i) + ">>>unrecognized image! %s - %s" % (str(result), str(fact))
        false_unrec += 1


print "true_rec", true_rec
print "false_rec", false_rec
print "true_unrec", true_unrec
print "false_unrec", false_unrec


#result = predict(W, b, training_img[image_index])
#sum_up(result, 4)

